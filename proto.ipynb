{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training CSV File\n",
    "\n",
    "Displays dataframe for verification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>vertical_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frames/frame_0000.jpg</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frames/frame_0001.jpg</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frames/frame_0002.jpg</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frames/frame_0003.jpg</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frames/frame_0004.jpg</td>\n",
       "      <td>-6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>frames/frame_0695.jpg</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>frames/frame_0696.jpg</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>frames/frame_0697.jpg</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>frames/frame_0698.jpg</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>frames/frame_0699.jpg</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                image_path  vertical_speed\n",
       "0    frames/frame_0000.jpg           -6.00\n",
       "1    frames/frame_0001.jpg           -6.00\n",
       "2    frames/frame_0002.jpg           -6.00\n",
       "3    frames/frame_0003.jpg           -6.00\n",
       "4    frames/frame_0004.jpg           -6.00\n",
       "..                     ...             ...\n",
       "695  frames/frame_0695.jpg            1.75\n",
       "696  frames/frame_0696.jpg            1.75\n",
       "697  frames/frame_0697.jpg            1.75\n",
       "698  frames/frame_0698.jpg            1.75\n",
       "699  frames/frame_0699.jpg            1.75\n",
       "\n",
       "[700 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training CSV file\n",
    "csv_file = 'training_labels.csv'\n",
    "training_df = pd.read_csv(csv_file)\n",
    "\n",
    "image_directory = 'vertical_speed_frames'\n",
    "training_df['image_path'] = training_df['image_path'].apply(lambda x: os.path.join(image_directory, x))\n",
    "\n",
    "training_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function - Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and apply labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images into a NumPy array\n",
    "images = np.array([load_image(file_path) for file_path in training_df['image_path']])\n",
    "\n",
    "\n",
    "# Encode the labels (assuming 'vertical_speed' is the column containing labels)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(training_df['vertical_speed'])\n",
    "\n",
    "# Optionally, one-hot encode the labels (if using categorical cross-entropy)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "one_hot_labels = tf.keras.utils.to_categorical(encoded_labels, num_classes)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, one_hot_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute - Run Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 74ms/step - loss: 3.5910 - accuracy: 0.1411 - val_loss: 3.4058 - val_accuracy: 0.1857\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 1s 69ms/step - loss: 2.9249 - accuracy: 0.2750 - val_loss: 2.6544 - val_accuracy: 0.3643\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 1.9625 - accuracy: 0.5071 - val_loss: 1.6937 - val_accuracy: 0.5643\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 1s 74ms/step - loss: 1.0653 - accuracy: 0.6821 - val_loss: 1.0904 - val_accuracy: 0.7071\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 0.6550 - accuracy: 0.8125 - val_loss: 0.8608 - val_accuracy: 0.7929\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 0.5672 - accuracy: 0.8214 - val_loss: 0.7057 - val_accuracy: 0.7714\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 0.4394 - accuracy: 0.8482 - val_loss: 0.5953 - val_accuracy: 0.8429\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 1s 72ms/step - loss: 0.2889 - accuracy: 0.9018 - val_loss: 0.5091 - val_accuracy: 0.8214\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.2888 - accuracy: 0.8929 - val_loss: 0.3490 - val_accuracy: 0.8643\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 0.3004 - accuracy: 0.8875 - val_loss: 0.4198 - val_accuracy: 0.8214\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.2379 - accuracy: 0.9107 - val_loss: 0.3293 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.2314 - accuracy: 0.9161 - val_loss: 0.4061 - val_accuracy: 0.8500\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.2488 - accuracy: 0.9125 - val_loss: 0.3154 - val_accuracy: 0.9071\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 0.1897 - accuracy: 0.9321 - val_loss: 0.3236 - val_accuracy: 0.8714\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.2127 - accuracy: 0.9018 - val_loss: 0.3337 - val_accuracy: 0.8571\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 1s 72ms/step - loss: 0.2251 - accuracy: 0.9143 - val_loss: 0.3357 - val_accuracy: 0.8643\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 1s 72ms/step - loss: 0.2078 - accuracy: 0.9107 - val_loss: 0.2583 - val_accuracy: 0.9071\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 1s 70ms/step - loss: 0.1787 - accuracy: 0.9232 - val_loss: 0.3979 - val_accuracy: 0.8571\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.2148 - accuracy: 0.9161 - val_loss: 0.2446 - val_accuracy: 0.8857\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 1s 71ms/step - loss: 0.1564 - accuracy: 0.9375 - val_loss: 0.2402 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 125, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes as needed\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Use appropriate loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "# You can use TensorFlow's `ImageDataGenerator` for data augmentation and preprocessing.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('vertical_speed_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
