{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training CSV File\n",
    "\n",
    "Displays dataframe for verification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>860.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>860.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>860.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>860.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>../media/daytime_full_cockpit_shift_perspectiv...</td>\n",
       "      <td>860.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3175 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path       x      y      w  \\\n",
       "0     ../media/daytime_full_cockpit_shift_perspectiv...  1060.0  650.0  130.0   \n",
       "1     ../media/daytime_full_cockpit_shift_perspectiv...  1060.0  650.0  130.0   \n",
       "2     ../media/daytime_full_cockpit_shift_perspectiv...  1060.0  650.0  130.0   \n",
       "3     ../media/daytime_full_cockpit_shift_perspectiv...  1060.0  650.0  130.0   \n",
       "4     ../media/daytime_full_cockpit_shift_perspectiv...  1060.0  650.0  130.0   \n",
       "...                                                 ...     ...    ...    ...   \n",
       "3170  ../media/daytime_full_cockpit_shift_perspectiv...   860.0  549.0   95.0   \n",
       "3171  ../media/daytime_full_cockpit_shift_perspectiv...   860.0  549.0   95.0   \n",
       "3172  ../media/daytime_full_cockpit_shift_perspectiv...   860.0  549.0   95.0   \n",
       "3173  ../media/daytime_full_cockpit_shift_perspectiv...   860.0  549.0   95.0   \n",
       "3174  ../media/daytime_full_cockpit_shift_perspectiv...   860.0  549.0   95.0   \n",
       "\n",
       "          h  \n",
       "0     120.0  \n",
       "1     120.0  \n",
       "2     120.0  \n",
       "3     120.0  \n",
       "4     120.0  \n",
       "...     ...  \n",
       "3170   91.0  \n",
       "3171   91.0  \n",
       "3172   91.0  \n",
       "3173   91.0  \n",
       "3174   91.0  \n",
       "\n",
       "[3175 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training CSV file\n",
    "csv_file = '../image_labels/bounding_box_label_test.csv'\n",
    "training_df = pd.read_csv(csv_file)\n",
    "\n",
    "image_directory = '../media/daytime_full_cockpit_shift_perspective/'\n",
    "training_df['image_path'] = training_df['image_path'].apply(lambda x: os.path.join(image_directory, x))\n",
    "\n",
    "training_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function - Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and apply labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize_image(file_path, scale_factor=0.5):\n",
    "    img = cv2.imread(file_path)\n",
    "    \n",
    "    # Get the original image dimensions\n",
    "    original_height, original_width = img.shape[:2]\n",
    "    \n",
    "    # Resize the image based on the scale factor\n",
    "    new_height = int(original_height * scale_factor)\n",
    "    new_width = int(original_width * scale_factor)\n",
    "    \n",
    "    img = cv2.resize(img, (new_width, new_height))\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Image - Width: 960, Height: 540\n"
     ]
    }
   ],
   "source": [
    "image_path = '../media/daytime_full_cockpit_shift_perspective/daytime_full_cockpit_shift_perspective_0000.jpg'\n",
    "resized_image = load_and_resize_image(image_path, scale_factor=0.5)\n",
    "\n",
    "print(f\"Resized Image - Width: {resized_image.shape[1]}, Height: {resized_image.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scale_factor \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load images into a NumPy array\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([load_and_resize_image(file_path, scale_factor) \u001b[39mfor\u001b[39;00m file_path \u001b[39min\u001b[39;00m training_df[\u001b[39m'\u001b[39m\u001b[39mimage_path\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Extract bounding box coordinates\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m bounding_boxes \u001b[39m=\u001b[39m training_df[[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;32m/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m scale_factor \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load images into a NumPy array\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([load_and_resize_image(file_path, scale_factor) \u001b[39mfor\u001b[39;00m file_path \u001b[39min\u001b[39;00m training_df[\u001b[39m'\u001b[39m\u001b[39mimage_path\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Extract bounding box coordinates\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m bounding_boxes \u001b[39m=\u001b[39m training_df[[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;32m/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m new_height \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(original_height \u001b[39m*\u001b[39m scale_factor)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m new_width \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(original_width \u001b[39m*\u001b[39m scale_factor)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(img, (new_width, new_height))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/matthewmunson/Documents/GitHub/instrument-identifier/src/train_model_bb.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scale_factor = 0.5\n",
    "\n",
    "# Load images into a NumPy array\n",
    "images = np.array([load_and_resize_image(file_path, scale_factor) for file_path in training_df['image_path']])\n",
    "\n",
    "# Extract bounding box coordinates\n",
    "bounding_boxes = training_df[['x', 'y', 'w', 'h']].values\n",
    "\n",
    "resized_bounding_boxes = bounding_boxes * scale_factor\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, bb_train, bb_val = train_test_split(\n",
    "    images, bounding_boxes, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch Notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute - Run Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80/80 [==============================] - 302s 4s/step - loss: 91259640.0000 - accuracy: 0.5067 - val_loss: 4832.7983 - val_accuracy: 0.6898\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 305s 4s/step - loss: 2638.0549 - accuracy: 0.7083 - val_loss: 2086.5127 - val_accuracy: 0.6929\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 295s 4s/step - loss: 1343.5165 - accuracy: 0.7346 - val_loss: 1338.6376 - val_accuracy: 0.7701\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 275s 3s/step - loss: 818.1143 - accuracy: 0.9008 - val_loss: 994.0252 - val_accuracy: 0.9953\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 255s 3s/step - loss: 573.7141 - accuracy: 0.9980 - val_loss: 823.2964 - val_accuracy: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture for bounding box regression\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(540, 960, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(4, activation='linear')  # 4 for bounding box coordinates (x, y, w, h)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, bb_train, epochs=5, validation_data=(X_val, bb_val))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('instrument_identifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
