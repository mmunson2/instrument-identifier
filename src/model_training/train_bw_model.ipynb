{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on black/white images\n",
    "\n",
    "This is a quick experiment to see if removing the color channel entirely will improve performance with daytime/nighttime lighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training CSV File\n",
    "\n",
    "Displays dataframe for verification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>vertical_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>../../media/vertical_speed_frames_expanded/day...</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2103 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  vertical_speed\n",
       "0     ../../media/vertical_speed_frames_expanded/day...            0.00\n",
       "1     ../../media/vertical_speed_frames_expanded/day...            0.00\n",
       "2     ../../media/vertical_speed_frames_expanded/day...            0.00\n",
       "3     ../../media/vertical_speed_frames_expanded/day...            0.00\n",
       "4     ../../media/vertical_speed_frames_expanded/day...            0.00\n",
       "...                                                 ...             ...\n",
       "2098  ../../media/vertical_speed_frames_expanded/day...            0.00\n",
       "2099  ../../media/vertical_speed_frames_expanded/day...           -0.25\n",
       "2100  ../../media/vertical_speed_frames_expanded/day...           -0.25\n",
       "2101  ../../media/vertical_speed_frames_expanded/day...           -0.25\n",
       "2102  ../../media/vertical_speed_frames_expanded/day...           -0.50\n",
       "\n",
       "[2103 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training CSV file\n",
    "csv_file = '../../image_labels/vertical_speed_labels/improved_vertical_speed_labels.csv'\n",
    "training_df = pd.read_csv(csv_file)\n",
    "\n",
    "image_directory = '../../media/vertical_speed_frames_expanded'\n",
    "training_df['image_path'] = training_df['image_path'].apply(lambda x: os.path.join(image_directory, x))\n",
    "\n",
    "training_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function - Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images and apply labels from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images into a NumPy array\n",
    "images = np.array([load_image(file_path) for file_path in training_df['image_path']])\n",
    "\n",
    "target_column_name = 'vertical_speed'\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(training_df[target_column_name])\n",
    "\n",
    "# Optionally, one-hot encode the labels (if using categorical cross-entropy)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "one_hot_labels = tf.keras.utils.to_categorical(encoded_labels, num_classes)\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, one_hot_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch Notes\n",
    "\n",
    "Best for airspeed - Epoch 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute - Run Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 3.4519 - accuracy: 0.1534 - val_loss: 2.5976 - val_accuracy: 0.3373\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 1.3761 - accuracy: 0.6356 - val_loss: 0.7254 - val_accuracy: 0.8029\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 4s 68ms/step - loss: 0.4566 - accuracy: 0.8460 - val_loss: 0.3667 - val_accuracy: 0.8860\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 4s 68ms/step - loss: 0.3195 - accuracy: 0.8805 - val_loss: 0.3319 - val_accuracy: 0.8860\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.2709 - accuracy: 0.8989 - val_loss: 0.2246 - val_accuracy: 0.9145\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.2485 - accuracy: 0.8971 - val_loss: 0.2890 - val_accuracy: 0.8955\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.2449 - accuracy: 0.9049 - val_loss: 0.2199 - val_accuracy: 0.9264\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.2402 - accuracy: 0.9084 - val_loss: 0.1833 - val_accuracy: 0.9287\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.1987 - accuracy: 0.9245 - val_loss: 0.1867 - val_accuracy: 0.9382\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.1910 - accuracy: 0.9269 - val_loss: 0.2221 - val_accuracy: 0.9406\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.1768 - accuracy: 0.9298 - val_loss: 0.2551 - val_accuracy: 0.9145\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 4s 71ms/step - loss: 0.1941 - accuracy: 0.9215 - val_loss: 0.2099 - val_accuracy: 0.9192\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.1770 - accuracy: 0.9209 - val_loss: 0.1567 - val_accuracy: 0.9287\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.1725 - accuracy: 0.9293 - val_loss: 0.1586 - val_accuracy: 0.9454\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.1706 - accuracy: 0.9304 - val_loss: 0.1729 - val_accuracy: 0.9359\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.1618 - accuracy: 0.9328 - val_loss: 0.1712 - val_accuracy: 0.9311\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 4s 71ms/step - loss: 0.1602 - accuracy: 0.9340 - val_loss: 0.1784 - val_accuracy: 0.9335\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 4s 71ms/step - loss: 0.1672 - accuracy: 0.9322 - val_loss: 0.1594 - val_accuracy: 0.9359\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 4s 71ms/step - loss: 0.1517 - accuracy: 0.9388 - val_loss: 0.1920 - val_accuracy: 0.9382\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.1497 - accuracy: 0.9340 - val_loss: 0.1548 - val_accuracy: 0.9501\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(120, 125, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes as needed\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Use appropriate loss function\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Load and preprocess your dataset\n",
    "# You can use TensorFlow's `ImageDataGenerator` for data augmentation and preprocessing.\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('regenerated_vertical_speed_model_20_epoch_bw.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
